// app/api/parse-file/[fileId]/route.ts

import { createServerSupabaseClient } from "@/lib/supabase/server"
import { NextResponse } from "next/server"
import { parse } from "csv-parse/sync"

function cleanNumericValue(value: string): number {
  if (!value) return Number.NaN
  return Number.parseFloat(value.replace(/[^0-9.-]/g, ""))
}

function guessCategoryType(name: string): "income" | "expense" | "debt" {
  const lower = name.toLowerCase()
  if (lower.includes("tax") || lower.includes("expense")) return "expense"
  if (lower.includes("wage") || lower.includes("income") || lower.includes("dividend")) return "income"
  if (lower.includes("loan") || lower.includes("debt")) return "debt"
  return "expense"
}

export async function POST(req: Request, { params }: { params: { fileId: string } }) {
  const supabase = createServerSupabaseClient()
  console.log("üîç Starting parse for file ID:", params.fileId)

  const {
    data: { user },
    error: authError,
  } = await supabase.auth.getUser()

  if (authError || !user) {
    console.error("‚ùå Auth error:", authError)
    return NextResponse.json({ error: "Unauthorized" }, { status: 401 })
  }

  const { data: file, error: fileFetchError } = await supabase
    .from("uploaded_files")
    .select("*")
    .eq("id", params.fileId)
    .single()

  if (fileFetchError || !file) {
    console.error("‚ùå File fetch error:", fileFetchError)
    return NextResponse.json({ error: "File not found" }, { status: 404 })
  }

  console.log("üìÑ Found file:", file.filename, "Path:", file.file_path)

  const { data: fileBlob, error: fileDownloadError } = await supabase.storage
    .from("cashflow-files")
    .download(file.file_path)

  if (fileDownloadError || !fileBlob) {
    console.error("‚ùå File download failed:", fileDownloadError)
    return NextResponse.json({ error: "File download failed" }, { status: 500 })
  }

  console.log("‚úÖ File downloaded successfully")

  // ‚¨áÔ∏è fallback entity logic
  let fallbackEntityId = file.entity_id
  if (!fallbackEntityId) {
    const { data: fallbackEntity, error: fallbackError } = await supabase
      .from("entities")
      .select("id")
      .eq("user_id", user.id)
      .eq("name", "Unassigned Entity")
      .maybeSingle()

    if (fallbackError) {
      console.error("‚ùå Error checking fallback entity:", fallbackError)
      return NextResponse.json({ error: "Entity lookup failed" }, { status: 500 })
    }

    if (fallbackEntity) {
      fallbackEntityId = fallbackEntity.id
      console.log("üè¢ Using existing fallback entity:", fallbackEntityId)
    } else {
      const { data: createdEntity, error: insertEntityError } = await supabase
        .from("entities")
        .insert({
          name: "Unassigned Entity",
          type: "business",
          user_id: user.id,
          metadata: {},
        })
        .select()
        .single()

      if (insertEntityError) {
        console.error("‚ùå Error inserting fallback entity:", insertEntityError)
        return NextResponse.json({ error: "Entity insert failed" }, { status: 500 })
      }

      fallbackEntityId = createdEntity.id
      console.log("üè¢ Created new fallback entity:", fallbackEntityId)
    }
  }

  try {
    const csvText = await fileBlob.text()
    console.log("üìä CSV content sample:", csvText.substring(0, 200) + "...")

    const rows = parse(csvText, { skip_empty_lines: true })
    const headers = rows[0]
    const categoryCol = 0

    const yearColumns: Record<number, number> = {}
    headers.forEach((col: string, i: number) => {
      const match = col.match(/\b(20\d{2})\b/)
      if (match) yearColumns[i] = Number.parseInt(match[1])
    })

    console.log("üìä CSV Headers:", headers)
    console.log("üìä Year columns detected:", yearColumns)
    console.log("üìä Total data rows:", rows.length - 1)

    if (Object.keys(yearColumns).length === 0) {
      console.error("‚ùå No year columns found.")
      return NextResponse.json({ error: "No year columns found." }, { status: 400 })
    }

    const normalizedRecords: any[] = []
    const errorRecords: any[] = []

    for (let i = 1; i < rows.length; i++) {
      const row = rows[i]
      console.log("üîç Row", i, "‚Üí", row)

      const categoryName = row[categoryCol]?.trim()

      if (!categoryName) {
        errorRecords.push({
          row_number: i,
          column_name: headers[categoryCol],
          error_type: "empty_cell",
          error_message: "Missing category name",
          raw_value: "",
        })
        continue
      }

      let { data: category, error: categoryFetchError } = await supabase
        .from("cashflow_categories")
        .select("*")
        .ilike("name", categoryName)
        .maybeSingle()

      if (categoryFetchError) {
        console.error("‚ùå Error fetching category:", categoryFetchError)
      }

      if (!category) {
        const newType = guessCategoryType(categoryName)
        console.log("üè∑Ô∏è Creating new category:", categoryName, "Type:", newType)

        const { data: created, error: insertError } = await supabase
          .from("cashflow_categories")
          .insert({ name: categoryName, type: newType, is_system: false })
          .select()
          .single()

        if (insertError) {
          console.error("‚ùå Category insert error:", insertError)
          continue
        }
        category = created
        console.log("‚úÖ Created category:", category.id)
      }

      for (const colIndex in yearColumns) {
        const rawValue = row[colIndex]
        const cleanedValue = cleanNumericValue(rawValue)
        const year = yearColumns[colIndex]

        console.log("üî¢ Processing value:", rawValue, "‚Üí", cleanedValue, "(year:", year + ")")

        if (isNaN(cleanedValue)) {
          errorRecords.push({
            row_number: i,
            column_name: headers[colIndex],
            error_type: "invalid_number",
            error_message: `Could not convert value: "${rawValue}"`,
            raw_value: rawValue,
          })
          continue
        }

        normalizedRecords.push({
          user_id: user.id,
          entity_id: fallbackEntityId,
          category_id: category.id,
          year,
          amount: cleanedValue,
          source_file_id: file.id,
          is_recurring: true,
        })
      }
    }

    console.log("‚úÖ Normalized rows to insert:", normalizedRecords.length)
    console.log("‚ö†Ô∏è Errors to log:", errorRecords.length)

    if (normalizedRecords.length > 0) {
      console.log("üíæ Inserting records sample:", normalizedRecords.slice(0, 2))

      const { data: insertedData, error: insertError } = await supabase
        .from("cashflow_records")
        .insert(normalizedRecords)
        .select()

      if (insertError) {
        console.error("‚ùå Error inserting records:", insertError)
        return NextResponse.json({ error: insertError.message }, { status: 500 })
      }

      console.log(`‚úÖ Successfully inserted ${insertedData?.length || 0} records`)
    }

    if (errorRecords.length > 0) {
      const enrichedErrors = errorRecords.map((e) => ({
        ...e,
        file_id: file.id,
        user_id: user.id,
      }))
      await supabase.from("parser_errors").insert(enrichedErrors)
    }

    await supabase
      .from("uploaded_files")
      .update({ status: "processed", processed_at: new Date().toISOString() })
      .eq("id", file.id)

    return NextResponse.json({
      message: "Parsed successfully",
      rows_inserted: normalizedRecords.length,
      rows_failed: errorRecords.length,
    })
  } catch (error) {
    console.error("‚ùå Unexpected error during parsing:", error)
    return NextResponse.json(
      {
        error: error instanceof Error ? error.message : "Unknown parsing error",
      },
      { status: 500 },
    )
  }
}
